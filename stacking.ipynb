{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "The idea in this notebook is to implement stacking methods on the kickstarter data. Hopefully, to reach the ultimate score.\n",
    "\n",
    "## Summary\n",
    "\n",
    "<font color = grey>\n",
    "\n",
    "- [With stolen models](#With-stolen-models)\n",
    " 1. [Importing and preprocessing data](#Importing-and-preprocessing-data)\n",
    " 2. [Training simple models withouth dimensionality reduction](#Training-simple-models-without-dimensionality-reduction)\n",
    "    2.a. [Vanilla logistic regression](#Vanilla-logistic-regression)\n",
    "    2.b. [Random forest](#Random-forest)\n",
    "    2.c. [XGBoost](#XGBoost)\n",
    " 3. [Stacking without dimensionality reduction](#Stacking-without-dimensionality-reduction)\n",
    "    3.a. [Logistic regression](#Logistic-regression)\n",
    "    3.b. [Neural network](#Neural-network)\n",
    "    3.c. [Neural network : the return](#Neural-network-:-the-return)\n",
    "    3.d. [Random forest top level](#Random-forest-top-level)\n",
    "    3.e. [SVM](#SVM)\n",
    "    3.f. [Majority vote](#Majority-vote)\n",
    "- [With our own models](#With-our-own-models)\n",
    "  1. [Stacking : logistic regression](#Stacking-:-logistic-regression)\n",
    "  2. [Stacking : neural network](#Stacking-:-neural-network)\n",
    "  3. [Stacking : majority vote](#Stacking-:-majority-vote)\n",
    "  \n",
    "- [Tests](#Tests)\n",
    "- [Back to training a few stolen models on the datasets](#Back-to-training-a-few-stolen-models-on-the-datasets)\n",
    "  1. [Datasets](#Datasets)\n",
    "  2. [Training](#Training)\n",
    "\n",
    "</font>\n",
    "\n",
    "## With stolen models\n",
    "\n",
    "First of all, we will design our functions with the help of the models stolen from the notebook found online. This will help us gain some time. In fact, the author already ran grid searches over her models (extremely expensive), so instead of starting over, we will just take the same models with the same parameters, without dimensionality reduction. After we built our proper functions, we will just have to start over with our one models that perform as accurately as possible on their own in order to get the best results with the full stack.\n",
    "\n",
    "### Importing and preprocessing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50) # Display up to 50 columns at a time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "plt.style.use('seaborn')\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12,5\n",
    "import glob # To read all csv files in the directory\n",
    "import seaborn as sns\n",
    "import calendar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_fscore_support\n",
    "import itertools\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import glob\n",
    "import pickle as pk\n",
    "from keras.models import load_model\n",
    "import os\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression as LR;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(f) for f in glob.glob('D:/Utilisateurs/Bastien/Documents/Cours/CentraleSupelec/Electifs/Machine Learning/Projet/kickstarter-analysis/data/Kickstarter*.csv')], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that are mostly null\n",
    "df.drop(['friends', 'is_backing', 'is_starred', 'permissions'], axis=1, inplace=True)\n",
    "\n",
    "# Dropping columns that aren't useful\n",
    "df.drop(['converted_pledged_amount', 'creator', 'currency', 'currency_symbol', 'currency_trailing_code', 'current_currency', 'fx_rate', 'photo', 'pledged', 'profile', 'slug', 'source_url', 'spotlight', 'state_changed_at', 'urls', 'usd_type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dates from unix to datetime\n",
    "cols_to_convert = ['created_at', 'deadline', 'launched_at']\n",
    "for c in cols_to_convert:\n",
    "    df[c] = pd.to_datetime(df[c], origin='unix', unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count length of each blurb\n",
    "df['blurb_length'] = df['blurb'].str.split().str.len()\n",
    "\n",
    "# Drop blurb variable\n",
    "df.drop('blurb', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the relevant sub-category section from the string\n",
    "f = lambda x: x['category'].split('/')[1].split('\",\"position')[0]\n",
    "df['sub_category'] = df.apply(f, axis=1)\n",
    "\n",
    "# Extracting the relevant category section from the string, and replacing the original category variable\n",
    "f = lambda x: x['category'].split('\"slug\":\"')[1].split('/')[0]\n",
    "df['category'] = df.apply(f, axis=1)\n",
    "f = lambda x: x['category'].split('\",\"position\"')[0] # Some categories do not have a sub-category, so do not have a '/' to split with\n",
    "df['category'] = df.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('disable_communication', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate new column 'usd_goal' as goal * static_usd_rate\n",
    "df['usd_goal'] = round(df['goal'] * df['static_usd_rate'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping goal and static_usd_rate\n",
    "df.drop(['goal', 'static_usd_rate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping location\n",
    "df.drop('location', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count length of each name\n",
    "df['name_length'] = df['name'].str.split().str.len()\n",
    "# Drop name variable\n",
    "df.drop('name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['usd_pledged'] = round(df['usd_pledged'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time between creating and launching a project\n",
    "df['creation_to_launch_days'] = df['launched_at'] - df['created_at']\n",
    "df['creation_to_launch_days'] = df['creation_to_launch_days'].dt.round('d').dt.days # Rounding to nearest days, then showing as number only\n",
    "# Or could show as number of hours:\n",
    "# df['creation_to_launch_hours'] = df['launched_at'] - df['created_at']\n",
    "# df['creation_to_launch_hours'] = df['creation_to_launch_hours'].dt.round('h') / np.timedelta64(1, 'h') \n",
    "\n",
    "# Campaign length\n",
    "df['campaign_days'] = df['deadline'] - df['launched_at']\n",
    "df['campaign_days'] = df['campaign_days'].dt.round('d').dt.days # Rounding to nearest days, then showing as number only\n",
    "\n",
    "# Launch day of week\n",
    "df['launch_day'] = df['launched_at'].dt.weekday_name\n",
    "\n",
    "# Deadline day of week\n",
    "df['deadline_day'] = df['deadline'].dt.weekday_name\n",
    "\n",
    "# Launch month\n",
    "df['launch_month'] = df['launched_at'].dt.month_name()\n",
    "\n",
    "# Deadline month\n",
    "df['deadline_month'] = df['deadline'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch time\n",
    "df['launch_hour'] = df['launched_at'].dt.hour # Extracting hour from launched_at\n",
    "\n",
    "def two_hour_launch(row):\n",
    "    '''Creates two hour bins from the launch_hour column'''\n",
    "    if row['launch_hour'] in (0,1):\n",
    "        return '12am-2am'\n",
    "    if row['launch_hour'] in (2,3):\n",
    "        return '2am-4am'\n",
    "    if row['launch_hour'] in (4,5):\n",
    "        return '4am-6am'\n",
    "    if row['launch_hour'] in (6,7):\n",
    "        return '6am-8am'\n",
    "    if row['launch_hour'] in (8,9):\n",
    "        return '8am-10am'\n",
    "    if row['launch_hour'] in (10,11):\n",
    "        return '10am-12pm'\n",
    "    if row['launch_hour'] in (12,13):\n",
    "        return '12pm-2pm'\n",
    "    if row['launch_hour'] in (14,15):\n",
    "        return '2pm-4pm'\n",
    "    if row['launch_hour'] in (16,17):\n",
    "        return '4pm-6pm'\n",
    "    if row['launch_hour'] in (18,19):\n",
    "        return '6pm-8pm'\n",
    "    if row['launch_hour'] in (20,21):\n",
    "        return '8pm-10pm'\n",
    "    if row['launch_hour'] in (22,23):\n",
    "        return '10pm-12am'\n",
    "    \n",
    "df['launch_time'] = df.apply(two_hour_launch, axis=1) # Calculates bins from launch_time\n",
    "\n",
    "df.drop('launch_hour', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deadline time\n",
    "df['deadline_hour'] = df['deadline'].dt.hour # Extracting hour from deadline\n",
    "\n",
    "def two_hour_deadline(row):\n",
    "    '''Creates two hour bins from the deadline_hour column'''\n",
    "    if row['deadline_hour'] in (0,1):\n",
    "        return '12am-2am'\n",
    "    if row['deadline_hour'] in (2,3):\n",
    "        return '2am-4am'\n",
    "    if row['deadline_hour'] in (4,5):\n",
    "        return '4am-6am'\n",
    "    if row['deadline_hour'] in (6,7):\n",
    "        return '6am-8am'\n",
    "    if row['deadline_hour'] in (8,9):\n",
    "        return '8am-10am'\n",
    "    if row['deadline_hour'] in (10,11):\n",
    "        return '10am-12pm'\n",
    "    if row['deadline_hour'] in (12,13):\n",
    "        return '12pm-2pm'\n",
    "    if row['deadline_hour'] in (14,15):\n",
    "        return '2pm-4pm'\n",
    "    if row['deadline_hour'] in (16,17):\n",
    "        return '4pm-6pm'\n",
    "    if row['deadline_hour'] in (18,19):\n",
    "        return '6pm-8pm'\n",
    "    if row['deadline_hour'] in (20,21):\n",
    "        return '8pm-10pm'\n",
    "    if row['deadline_hour'] in (22,23):\n",
    "        return '10pm-12am'\n",
    "    \n",
    "df['deadline_time'] = df.apply(two_hour_deadline, axis=1) # Calculates bins from launch_time\n",
    "\n",
    "df.drop('deadline_hour', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean pledge per backer\n",
    "df['pledge_per_backer'] = round(df['usd_pledged']/df['backers_count'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing null values for blurb_length with 0\n",
    "df.blurb_length.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping projects which are not successes or failures\n",
    "df = df[df['state'].isin(['successful', 'failed'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 192664 projects in the dataset, there are 23685 which are listed more than once.\n",
      "Of these, 23674 have every value in common between duplicates.\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates of individual projects, and sorting by id\n",
    "duplicates = df[df.duplicated(subset='id')]\n",
    "print(f\"Of the {len(df)} projects in the dataset, there are {len(df[df.duplicated(subset='id')])} which are listed more than once.\")\n",
    "print(f\"Of these, {len(df[df.duplicated()])} have every value in common between duplicates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Dropping duplicates which have every value in common\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated = df[df.duplicated(subset='id', keep=False)].sort_values(by='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(subset='id', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backers_count</th>\n",
       "      <th>category</th>\n",
       "      <th>country</th>\n",
       "      <th>created_at</th>\n",
       "      <th>deadline</th>\n",
       "      <th>is_starrable</th>\n",
       "      <th>launched_at</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>state</th>\n",
       "      <th>usd_pledged</th>\n",
       "      <th>blurb_length</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>usd_goal</th>\n",
       "      <th>name_length</th>\n",
       "      <th>creation_to_launch_days</th>\n",
       "      <th>campaign_days</th>\n",
       "      <th>launch_day</th>\n",
       "      <th>deadline_day</th>\n",
       "      <th>launch_month</th>\n",
       "      <th>deadline_month</th>\n",
       "      <th>launch_time</th>\n",
       "      <th>deadline_time</th>\n",
       "      <th>pledge_per_backer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287514992</th>\n",
       "      <td>21</td>\n",
       "      <td>music</td>\n",
       "      <td>US</td>\n",
       "      <td>2013-12-21 21:01:30</td>\n",
       "      <td>2014-02-08 22:37:26</td>\n",
       "      <td>False</td>\n",
       "      <td>2013-12-25 22:37:26</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>802.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>rock</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>December</td>\n",
       "      <td>February</td>\n",
       "      <td>10pm-12am</td>\n",
       "      <td>10pm-12am</td>\n",
       "      <td>38.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385129759</th>\n",
       "      <td>97</td>\n",
       "      <td>art</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-02-08 21:02:48</td>\n",
       "      <td>2019-03-05 16:00:11</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-02-13 16:00:11</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>2259.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>mixed media</td>\n",
       "      <td>400.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>February</td>\n",
       "      <td>March</td>\n",
       "      <td>4pm-6pm</td>\n",
       "      <td>4pm-6pm</td>\n",
       "      <td>23.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681033598</th>\n",
       "      <td>88</td>\n",
       "      <td>photography</td>\n",
       "      <td>US</td>\n",
       "      <td>2016-10-23 17:06:24</td>\n",
       "      <td>2016-12-01 15:58:50</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-11-01 14:58:50</td>\n",
       "      <td>True</td>\n",
       "      <td>successful</td>\n",
       "      <td>29638.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>photobooks</td>\n",
       "      <td>27224.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "      <td>December</td>\n",
       "      <td>2pm-4pm</td>\n",
       "      <td>2pm-4pm</td>\n",
       "      <td>336.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031782682</th>\n",
       "      <td>193</td>\n",
       "      <td>fashion</td>\n",
       "      <td>IT</td>\n",
       "      <td>2018-10-24 08:32:00</td>\n",
       "      <td>2018-12-08 22:59:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-10-27 23:56:22</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>49075.15</td>\n",
       "      <td>13.0</td>\n",
       "      <td>footwear</td>\n",
       "      <td>45461.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>October</td>\n",
       "      <td>December</td>\n",
       "      <td>10pm-12am</td>\n",
       "      <td>10pm-12am</td>\n",
       "      <td>254.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904085819</th>\n",
       "      <td>20</td>\n",
       "      <td>technology</td>\n",
       "      <td>US</td>\n",
       "      <td>2015-03-07 05:35:17</td>\n",
       "      <td>2015-04-08 16:36:57</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-03-09 16:36:57</td>\n",
       "      <td>False</td>\n",
       "      <td>failed</td>\n",
       "      <td>549.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>software</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>March</td>\n",
       "      <td>April</td>\n",
       "      <td>4pm-6pm</td>\n",
       "      <td>4pm-6pm</td>\n",
       "      <td>27.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            backers_count     category country          created_at  \\\n",
       "id                                                                   \n",
       "287514992              21        music      US 2013-12-21 21:01:30   \n",
       "385129759              97          art      US 2019-02-08 21:02:48   \n",
       "681033598              88  photography      US 2016-10-23 17:06:24   \n",
       "1031782682            193      fashion      IT 2018-10-24 08:32:00   \n",
       "904085819              20   technology      US 2015-03-07 05:35:17   \n",
       "\n",
       "                      deadline  is_starrable         launched_at  staff_pick  \\\n",
       "id                                                                             \n",
       "287514992  2014-02-08 22:37:26         False 2013-12-25 22:37:26       False   \n",
       "385129759  2019-03-05 16:00:11         False 2019-02-13 16:00:11       False   \n",
       "681033598  2016-12-01 15:58:50         False 2016-11-01 14:58:50        True   \n",
       "1031782682 2018-12-08 22:59:00         False 2018-10-27 23:56:22       False   \n",
       "904085819  2015-04-08 16:36:57         False 2015-03-09 16:36:57       False   \n",
       "\n",
       "                 state  usd_pledged  blurb_length sub_category  usd_goal  \\\n",
       "id                                                                         \n",
       "287514992   successful       802.00          26.0         rock     200.0   \n",
       "385129759   successful      2259.00           9.0  mixed media     400.0   \n",
       "681033598   successful     29638.00          25.0   photobooks   27224.0   \n",
       "1031782682  successful     49075.15          13.0     footwear   45461.0   \n",
       "904085819       failed       549.00          22.0     software    1000.0   \n",
       "\n",
       "            name_length  creation_to_launch_days  campaign_days launch_day  \\\n",
       "id                                                                           \n",
       "287514992             4                        4             45  Wednesday   \n",
       "385129759             5                        5             20  Wednesday   \n",
       "681033598             9                        9             30    Tuesday   \n",
       "1031782682            5                        4             42   Saturday   \n",
       "904085819             4                        2             30     Monday   \n",
       "\n",
       "           deadline_day launch_month deadline_month launch_time deadline_time  \\\n",
       "id                                                                              \n",
       "287514992      Saturday     December       February   10pm-12am     10pm-12am   \n",
       "385129759       Tuesday     February          March     4pm-6pm       4pm-6pm   \n",
       "681033598      Thursday     November       December     2pm-4pm       2pm-4pm   \n",
       "1031782682     Saturday      October       December   10pm-12am     10pm-12am   \n",
       "904085819     Wednesday        March          April     4pm-6pm       4pm-6pm   \n",
       "\n",
       "            pledge_per_backer  \n",
       "id                             \n",
       "287514992               38.19  \n",
       "385129759               23.29  \n",
       "681033598              336.80  \n",
       "1031782682             254.28  \n",
       "904085819               27.45  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the id column as the index\n",
    "df.set_index('id', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>country</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>state</th>\n",
       "      <th>blurb_length</th>\n",
       "      <th>usd_goal</th>\n",
       "      <th>name_length</th>\n",
       "      <th>creation_to_launch_days</th>\n",
       "      <th>campaign_days</th>\n",
       "      <th>launch_day</th>\n",
       "      <th>deadline_day</th>\n",
       "      <th>launch_month</th>\n",
       "      <th>deadline_month</th>\n",
       "      <th>launch_time</th>\n",
       "      <th>deadline_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287514992</th>\n",
       "      <td>music</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>26.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>December</td>\n",
       "      <td>February</td>\n",
       "      <td>10pm-12am</td>\n",
       "      <td>10pm-12am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385129759</th>\n",
       "      <td>art</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>9.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>February</td>\n",
       "      <td>March</td>\n",
       "      <td>4pm-6pm</td>\n",
       "      <td>4pm-6pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681033598</th>\n",
       "      <td>photography</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>successful</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27224.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "      <td>December</td>\n",
       "      <td>2pm-4pm</td>\n",
       "      <td>2pm-4pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031782682</th>\n",
       "      <td>fashion</td>\n",
       "      <td>IT</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>13.0</td>\n",
       "      <td>45461.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>October</td>\n",
       "      <td>December</td>\n",
       "      <td>10pm-12am</td>\n",
       "      <td>10pm-12am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904085819</th>\n",
       "      <td>technology</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>failed</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>March</td>\n",
       "      <td>April</td>\n",
       "      <td>4pm-6pm</td>\n",
       "      <td>4pm-6pm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               category country  staff_pick       state  blurb_length  \\\n",
       "id                                                                      \n",
       "287514992         music      US       False  successful          26.0   \n",
       "385129759           art      US       False  successful           9.0   \n",
       "681033598   photography      US        True  successful          25.0   \n",
       "1031782682      fashion      IT       False  successful          13.0   \n",
       "904085819    technology      US       False      failed          22.0   \n",
       "\n",
       "            usd_goal  name_length  creation_to_launch_days  campaign_days  \\\n",
       "id                                                                          \n",
       "287514992      200.0            4                        4             45   \n",
       "385129759      400.0            5                        5             20   \n",
       "681033598    27224.0            9                        9             30   \n",
       "1031782682   45461.0            5                        4             42   \n",
       "904085819     1000.0            4                        2             30   \n",
       "\n",
       "           launch_day deadline_day launch_month deadline_month launch_time  \\\n",
       "id                                                                           \n",
       "287514992   Wednesday     Saturday     December       February   10pm-12am   \n",
       "385129759   Wednesday      Tuesday     February          March     4pm-6pm   \n",
       "681033598     Tuesday     Thursday     November       December     2pm-4pm   \n",
       "1031782682   Saturday     Saturday      October       December   10pm-12am   \n",
       "904085819      Monday    Wednesday        March          April     4pm-6pm   \n",
       "\n",
       "           deadline_time  \n",
       "id                        \n",
       "287514992      10pm-12am  \n",
       "385129759        4pm-6pm  \n",
       "681033598        2pm-4pm  \n",
       "1031782682     10pm-12am  \n",
       "904085819        4pm-6pm  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping columns and creating new dataframe\n",
    "df_transformed = df.drop(['backers_count', 'created_at', 'deadline', 'is_starrable', 'launched_at', 'usd_pledged', 'sub_category', 'pledge_per_backer'], axis=1)\n",
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed['state'] = df_transformed['state'].replace({'failed': 0, 'successful': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting boolean features to string to include them in one-hot encoding\n",
    "df_transformed['staff_pick'] = df_transformed['staff_pick'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables\n",
    "df_transformed = pd.get_dummies(df_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us <font color = purple>**log-transform**</font> the data on the appropriate features. It allows better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing skewed distributions\n",
    "cols_to_log = ['creation_to_launch_days', 'name_length', 'usd_goal']\n",
    "# Replacing 0s with 0.01 and log-transforming\n",
    "for col in cols_to_log:\n",
    "    df_transformed[col] = df_transformed[col].astype('float64').replace(0.0, 0.01)\n",
    "    df_transformed[col] = np.log(df_transformed[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_transformed.drop('state', axis=1)\n",
    "y = df_transformed.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally save the datasets (both obvservations and labels in seperate datasets) in the right sub folder so as not to redo the whole data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('datasets/observations.csv', header=X.columns )\n",
    "y = y.values\n",
    "y = pd.DataFrame(y)\n",
    "y.to_csv('datasets/labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we should separate the dataset in three similar subsets for further trainings, validation and tests. More specifically, one part will be used to train the level 0 models, the second part will be used to train the level 1 model and the last subset will be used to test the whole stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X.values.shape[0]\n",
    "n_subset = n_samples//3\n",
    "\n",
    "X1 = X.iloc[:n_subset,:]\n",
    "X2 = X.iloc[n_subset:2*n_subset,:]\n",
    "X3 = X.iloc[2*n_subset:,:]\n",
    "\n",
    "y1 = y.iloc[:n_subset,:]\n",
    "y2 = y.iloc[n_subset:2*n_subset,:]\n",
    "y3 = y.iloc[2*n_subset:,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.to_csv('datasets/observations1.csv', header=X1.columns )\n",
    "X2.to_csv('datasets/observations2.csv', header=X2.columns )\n",
    "X3.to_csv('datasets/observations3.csv', header=X3.columns )\n",
    "y1.to_csv('datasets/labels1.csv')\n",
    "y2.to_csv('datasets/labels2.csv')\n",
    "y3.to_csv('datasets/labels3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training simple models without dimensionality reduction\n",
    "Now, we should train each of the model specified in the model notebook, on each of the subsets. However, note that the data was <font color=purple>**log-transformed**</font> to accomplish better results.\n",
    "#### Vanilla logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting logistic regression models with default parameters\n",
    "logreg1 = LogisticRegression()\n",
    "logreg1.fit(X1,y1)\n",
    "logreg2 = LogisticRegression()\n",
    "logreg2.fit(X2,y2)\n",
    "logreg3 = LogisticRegression()\n",
    "logreg3.fit(X3,y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should save the trained models in the proper sub folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_list = [logreg1,logreg2,logreg3]\n",
    "\n",
    "for i in range(3):\n",
    "    with open('stacking_test/logreg'+str(i+1)+'.txt','wb') as fichier:\n",
    "        pickler = pk.Pickler(fichier)\n",
    "        pickler.dump(logistic_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=35, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=0.001,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=400,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(max_depth=35, min_samples_split=0.001, n_estimators=400)\n",
    "rf1.fit(X1, y1)\n",
    "rf2 = RandomForestClassifier(max_depth=35, min_samples_split=0.001, n_estimators=400)\n",
    "rf2.fit(X2, y2)\n",
    "rf3 = RandomForestClassifier(max_depth=35, min_samples_split=0.001, n_estimators=400)\n",
    "rf3.fit(X3, y3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_list = [rf1,rf2,rf3]\n",
    "for i in range(3):\n",
    "    with open('stacking_test/random_forest_'+str(i+1)+'.txt','wb') as fichier:\n",
    "        pickler = pk.Pickler(fichier)\n",
    "        pickler.dump(rf_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=35,\n",
       "              min_child_weight=100, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=0.7, verbosity=1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1 = xgb.XGBClassifier(learning_rate=0.1, max_depth=35, min_child_weight=100, n_estimators=100, subsample=0.7)\n",
    "xgb1.fit(X1, y1)\n",
    "xgb2 = xgb.XGBClassifier(learning_rate=0.1, max_depth=35, min_child_weight=100, n_estimators=100, subsample=0.7)\n",
    "xgb2.fit(X2, y2)\n",
    "xgb3 = xgb.XGBClassifier(learning_rate=0.1, max_depth=35, min_child_weight=100, n_estimators=100, subsample=0.7)\n",
    "xgb3.fit(X3, y3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_list = [xgb1,xgb2,xgb3]\n",
    "for i in range(3):\n",
    "    with open('stacking_test/xgb_'+str(i+1)+'.txt','wb') as fichier:\n",
    "        pickler = pk.Pickler(fichier)\n",
    "        pickler.dump(xgb_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking without dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_dataset(models, inputX, scaler = None, fit_scaler = False):\n",
    "    \"\"\"\n",
    "    Input : list of learners, np.array, sklearn object, bool\n",
    "    Output: np.array\n",
    "    The function takes a list of pretrained models, the training observations and eventually a standard scaler to scale \n",
    "    the stacked data. The last boolean is an indicator to tell if the standard scaler ought to be trained or if it has already\n",
    "    been. Then it returns the concatenated predictions\n",
    "    of each and every model in a flattened array. The output will be the input of the level 1 model to train with\n",
    "    trainStack\n",
    "    \"\"\"\n",
    "    stackX = None\n",
    "    for model in models:\n",
    "        # make prediction\n",
    "        yhat = model.predict(inputX)\n",
    "        # stack predictions into [rows, members, probabilities]\n",
    "        if stackX is None:\n",
    "            stackX = yhat\n",
    "        else:\n",
    "            stackX = np.dstack((stackX, yhat))\n",
    "    # flatten predictions to [rows, members x probabilities]\n",
    "    if len(models) > 1:\n",
    "        stackX = stackX.reshape((stackX.shape[1], stackX.shape[2]))\n",
    "        \n",
    "#     print(\"Il y a {0} modèles, le format des observations est : {1} et celui des observations empilées est : {2}\".format(len(models), inputX.shape, stackX.shape))\n",
    "#     print(\"Les cinq premières lignes ressemblent à ceci : {}\".format(stackX[:5,:]))\n",
    "\n",
    "    if scaler is not None:\n",
    "        if fit_scaler:\n",
    "            stackX = scaler.fit_transform(stackX)\n",
    "        else:\n",
    "            stackX = scaler.transform(stackX)\n",
    "    \n",
    "#     print('Les résultats agglomérés des modèles ressemblent à ça : {}'.format(stackX[:5,:]))\n",
    "    return stackX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainStack(first_models, final_model, X_train, y_train, is_MLP = False, epochs = 300, scaler = None, fit_scaler = False):\n",
    "    \"\"\"\n",
    "    Input : list of learners, learner, np.array, np.array, bool, int, sklearn object, bool\n",
    "    Output : learner\n",
    "    The function takes the level 0 trained learners, the level 1 learner to train, the training observations, the \n",
    "    training labels, the boolean telling whether or not the top-level classifier is a Multi-Layer Perceptron and the integer\n",
    "    corresponding to the number of training epochs if we have an MLP. The two last arguments are a respectively a \n",
    "    standard scaler in case we need to scale our data and a boolean telling whether or not it has to be trained.\n",
    "    It returns the level 1 trained model.\n",
    "    \"\"\"\n",
    "    X_stacked = stacked_dataset(first_models, X_train, scaler = scaler, fit_scaler = fit_scaler)\n",
    "    \n",
    "    if is_MLP:\n",
    "        y_train_categ = to_categorical(y_train)\n",
    "#         print(\"Les labels pour l'entrainement ont cette forme : {}\".format(y_train_categ[:5]))\n",
    "        final_model.fit(X_stacked, y_train_categ, epochs = epochs, verbose = 0)\n",
    "    else:\n",
    "        final_model.fit(X_stacked, y_train)\n",
    "    \n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictStack(first_models, final_model, X_test, scaler = None):\n",
    "    \"\"\"\n",
    "    Input : list of learners, learner, array-like, sklearn object\n",
    "    Output : array-like\n",
    "    The function takes the first-level trained models, the top-level trained model, the test set and eventually a scaler \n",
    "    that scales the X_test data with a pretrained scaler (trained on the training data) and returns \n",
    "    the predictions of the stack on the test set.\n",
    "    \"\"\"\n",
    "    X_stacked = stacked_dataset(first_models, X_test, scaler = scaler)\n",
    "        \n",
    "    y_predicted = final_model.predict(X_stacked)\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression\n",
    "We will use the logistic regression as the top-level trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the pretrained models\n",
    "logreg1, rf1, xgb1 = None, None, None\n",
    "\n",
    "with open('stacking_test/logreg1.txt','rb') as fichier:\n",
    "    pickler = pk.Unpickler(fichier)\n",
    "    logreg1 = pickler.load()\n",
    "\n",
    "with open('stacking_test/random_forest_1.txt','rb') as fichier:\n",
    "    pickler = pk.Unpickler(fichier)\n",
    "    rf1 = pickler.load()\n",
    "    \n",
    "with open('stacking_test/xgb_1.txt','rb') as fichier:\n",
    "    pickler = pk.Unpickler(fichier)\n",
    "    xgb1 = pickler.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets. Since the models were trained on the first part of the dataset, we must choose different datasets this\n",
    "# time, for instance the second subsets\n",
    "X_train = pd.read_csv('datasets/observations2.csv')\n",
    "y_train = pd.read_csv('datasets/labels2.csv')\n",
    "X_train.drop('id',axis=1,inplace=True)\n",
    "y_train.drop('Unnamed: 0',axis=1,inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model1 = LogisticRegression();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 3 modèles, le format des observations est : (56326, 106) et celui des observations empilées est : (56326, 3)\n",
      "Les cinq premières lignes ressemblent à ceci : [[0 0 0]\n",
      " [1 1 0]\n",
      " [1 1 1]\n",
      " [0 0 0]\n",
      " [1 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "stack1 = trainStack([logreg1, rf1, xgb1], top_model1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to import the test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('datasets/observations3.csv')\n",
    "y_test = pd.read_csv('datasets/labels3.csv')\n",
    "X_test.drop('id',axis=1,inplace=True)\n",
    "y_test.drop('Unnamed: 0',axis=1,inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 3 modèles, le format des observations est : (56327, 106) et celui des observations empilées est : (56327, 3)\n",
      "Les cinq premières lignes ressemblent à ceci : [[1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_predicted = predictStack([logreg1, rf1, xgb1], stack1, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 3 modèles, le format des observations est : (56326, 106) et celui des observations empilées est : (56326, 3)\n",
      "Les cinq premières lignes ressemblent à ceci : [[0 0 0]\n",
      " [1 1 0]\n",
      " [1 1 1]\n",
      " [0 0 0]\n",
      " [1 1 1]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.747522</td>\n",
       "      <td>0.736698</td>\n",
       "      <td>0.731683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.746376</td>\n",
       "      <td>0.744221</td>\n",
       "      <td>0.738814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision    Recall  F1_score\n",
       "Test    0.747522  0.736698  0.731683\n",
       "Train   0.746376  0.744221  0.738814"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the results\n",
    "y_train_pred = predictStack([logreg1, rf1, xgb1], stack1, X_train)\n",
    "\n",
    "stack1_test_precision, stack1_test_recall, stack1_test_f1score, stack1_test_support = precision_recall_fscore_support(y_test, y_predicted, average='weighted')\n",
    "stack1_train_precision, stack1_train_recall, stack1_train_f1score, stack1_train_support = precision_recall_fscore_support(y_train, y_train_pred, average='weighted')\n",
    "stack1_results = {'Precision':[stack1_test_precision, stack1_train_precision], 'Recall':[stack1_test_recall, stack1_train_recall], 'F1_score': [stack1_test_f1score, stack1_train_f1score]}\n",
    "stack1_results = pd.DataFrame(stack1_results, index=['Test','Train'])\n",
    "stack1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the first trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stacking_test/stack_logreg.txt','wb') as fichier:\n",
    "    pickler = pk.Pickler(fichier)\n",
    "    pickler.dump(stack1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should renew the experiment with models trained on different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network\n",
    "This time, we will use a neural network as a top-level learner. **Beware**, we will use <font color = purple>TensorFlow and Keras</font> to implemant our neural networks. Both packages **must** be used in a virutal environment with **Python 3.6**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model2 = Sequential()\n",
    "top_model2.add(Dense(25, input_dim=3, activation='relu'))\n",
    "top_model2.add(Dense(2, activation='softmax'))\n",
    "top_model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 3 modèles, le format des observations est : (56326, 106) et celui des observations empilées est : (56326, 3)\n",
      "Les cinq premières lignes ressemblent à ceci : [[0 0 0]\n",
      " [1 1 0]\n",
      " [1 1 1]\n",
      " [0 0 0]\n",
      " [1 1 1]]\n",
      "Les labels pour l'entrainement ont cette forme : [[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "WARNING:tensorflow:From D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "stack2 = trainStack([logreg1, rf1, xgb1], top_model2, X_train, y_train, is_MLP = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'stacking_test/stack_MLP1.h5'\n",
    "stack2.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 3 modèles, le format des observations est : (56327, 106) et celui des observations empilées est : (56327, 3)\n",
      "Les cinq premières lignes ressemblent à ceci : [[1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_predicted2 = predictStack([logreg1, rf1, xgb1], stack2, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les prédictions retournées par le réseau de neurone sont en fait des probabilités d'appartenance à une classe ou à une autre\n",
    "Plutôt que de le réentrainer (c'est très long), nous remplaceront la ligne de deux valeurs par un zéro si la valeur de la première colonne est la plus grande, par un 1 si la valeur de la deuxièe colonne est la plus grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 3 modèles, le format des observations est : (56326, 106) et celui des observations empilées est : (56326, 3)\n",
      "Les cinq premières lignes ressemblent à ceci : [[0 0 0]\n",
      " [1 1 0]\n",
      " [1 1 1]\n",
      " [0 0 0]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_flat2 = np.array(y_predicted2.shape[0]*[0])\n",
    "\n",
    "\n",
    "for i in range(y_predicted2.shape[0]):\n",
    "    if y_predicted2[i,0] < y_predicted2[i,1]:\n",
    "        y_pred_flat2[i] = 1\n",
    "        \n",
    "y_train_pred2 = predictStack([logreg1, rf1, xgb1], stack2, X_train)\n",
    "y_train_pred_flat2 = np.array(y_train_pred2.shape[0]*[0])\n",
    "\n",
    "for i in range(y_train_pred2.shape[0]):\n",
    "    if y_train_pred2[i,0] < y_train_pred2[i,1]:\n",
    "        y_train_pred_flat2[i] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.745820</td>\n",
       "      <td>0.740853</td>\n",
       "      <td>0.738060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.746055</td>\n",
       "      <td>0.746636</td>\n",
       "      <td>0.743767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision    Recall  F1_score\n",
       "Test    0.745820  0.740853  0.738060\n",
       "Train   0.746055  0.746636  0.743767"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the results\n",
    "stack2_test_precision, stack2_test_recall, stack2_test_f1score, stack2_test_support = precision_recall_fscore_support(y_test, y_pred_flat2, average='weighted')\n",
    "stack2_train_precision, stack2_train_recall, stack2_train_f1score, stack2_train_support = precision_recall_fscore_support(y_train, y_train_pred_flat2, average='weighted')\n",
    "stack2_results = {'Precision':[stack2_test_precision, stack2_train_precision], 'Recall':[stack2_test_recall, stack2_train_recall], 'F1_score': [stack2_test_f1score, stack2_train_f1score]}\n",
    "stack2_results = pd.DataFrame(stack2_results, index=['Test','Train'])\n",
    "stack2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision is worse than before but the F1-score rose from 0.731 to 0.738 which is not a considerable improvement. Fortunately, we cannot lay the blame on overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network : the return\n",
    " This time, we'll try a different architecture. Maybe we don't need 25 neurons in the first layer. However, it is probably useless to add many more layers. However, we will try out a three-layer perceptron and see how it goes. We will try different loss functions as well. And finally, we will train our exemples on smaller datasets to compute adequate results in reasonable time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, since it proved useful to transform the results computed by the perceptron (probabilities instead of classes), we will build a function to do the same thing. We will need a function to display the final results as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilitiesToClass(array):\n",
    "    \"\"\"\n",
    "    Input: np.array of size (n,2)\n",
    "    Output : np.array of size (n,)\n",
    "    The function takes the array whose lines are the observations and column values correspond to the probability of belonging \n",
    "    to a given class. If the probability in a given column is superior to 0.5, then we will return the number of that class. \n",
    "    For instance : [0.33,0.66] for an observation will render [1] and [0.7,0.3] will render [0].\n",
    "    \"\"\"\n",
    "    res = np.array(array.shape[0]*[0])\n",
    "    for i in range(array.shape[0]):\n",
    "        if array[i,1] > array[i,0]:\n",
    "            res[i] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayPerformances(y_test, y_test_pred, y_train, y_train_pred):\n",
    "    \"\"\"\n",
    "    Input: np.array (n,1), np.array (n,1), np.array (N,1), np.array (N,1)\n",
    "    Output : pd.DataFrame\n",
    "    The function takes the labels from the training set, the predicted labels, and the same for the test set. It returns\n",
    "    a DataFrame containing the values on each data set of the precision, the recall and the f1-score.\n",
    "    \"\"\"\n",
    "    test_precision, test_recall, test_f1score, test_support = precision_recall_fscore_support(y_test, y_test_pred, average='weighted')\n",
    "    train_precision, train_recall, train_f1score, train_support = precision_recall_fscore_support(y_train, y_train_pred, average='weighted')\n",
    "    results = {'Precision':[test_precision, train_precision], 'Recall':[test_recall, train_recall], 'F1_score': [test_f1score, train_f1score]}\n",
    "    results = pd.DataFrame(results, index=['Test','Train'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try out a new neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model3 = Sequential()\n",
    "top_model3.add(Dense(7, input_dim=3, activation='relu'))\n",
    "top_model3.add(Dense(7, activation='relu'))\n",
    "top_model3.add(Dense(2, activation='softmax'))\n",
    "top_model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train this perceptron on only 2000 samples\n",
    "stack3 = trainStack([logreg1, rf1, xgb1], top_model3, X_train.iloc[:2000,:], y_train.iloc[:2000,:], is_MLP = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's save the trained model\n",
    "filename = 'stacking_test/stack_MLP2.h5'\n",
    "stack3.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred3 = predictStack([logreg1, rf1, xgb1], stack3, X_test.iloc[:1000,:])\n",
    "y_test_pred_flat3 = probabilitiesToClass(y_test_pred3)\n",
    "y_train_pred3 = predictStack([logreg1, rf1, xgb1], stack3, X_train.iloc[:2000,:])\n",
    "y_train_pred_flat3 = probabilitiesToClass(y_train_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.737591</td>\n",
       "      <td>0.7340</td>\n",
       "      <td>0.728333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.760837</td>\n",
       "      <td>0.7645</td>\n",
       "      <td>0.758654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision  Recall  F1_score\n",
       "Test    0.737591  0.7340  0.728333\n",
       "Train   0.760837  0.7645  0.758654"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3 = displayPerformances(y_test.iloc[:1000,:], y_test_pred_flat3, y_train.iloc[:2000,:], y_train_pred_flat3)\n",
    "res3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stack overfitted this time. It does not make a huge difference, however, it is worse than previous computations. Let us try the same neural network as before but with the new loss function : <font color = purple>binary_crossentropy</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model4 = Sequential()\n",
    "top_model4.add(Dense(25, input_dim=3, activation='relu'))\n",
    "top_model4.add(Dense(2, activation='softmax'))\n",
    "top_model4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train this perceptron on only 2000 samples\n",
    "stack4 = trainStack([logreg1, rf1, xgb1], top_model4, X_train.iloc[:4000,:], y_train.iloc[:4000,:], is_MLP = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's save the trained model\n",
    "filename = 'stacking_test/stack_MLP3.h5'\n",
    "stack4.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred4 = predictStack([logreg1, rf1, xgb1], stack4, X_test.iloc[:2000,:])\n",
    "y_test_pred_flat4 = probabilitiesToClass(y_test_pred4)\n",
    "y_train_pred4 = predictStack([logreg1, rf1, xgb1], stack4, X_train.iloc[:4000,:])\n",
    "y_train_pred_flat4 = probabilitiesToClass(y_train_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.740403</td>\n",
       "      <td>0.73950</td>\n",
       "      <td>0.734094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.749134</td>\n",
       "      <td>0.75125</td>\n",
       "      <td>0.747795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision   Recall  F1_score\n",
       "Test    0.740403  0.73950  0.734094\n",
       "Train   0.749134  0.75125  0.747795"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res4 = displayPerformances(y_test.iloc[:2000,:], y_test_pred_flat4, y_train.iloc[:4000,:], y_train_pred_flat4)\n",
    "res4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This neural network is obviously better since it does not overfit and has better results on the test set. However, it is a bit less efficient than the one trained on the full training set. Unfortunately, no sign of a breakthrough yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest top level\n",
    "What if the top-level learner was a random forest ? This algorithm has proved indecently efficient in past classification exercises. It is high time we tried it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model5 = RandomForestClassifier(max_depth=10, min_samples_split=0.001, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:19: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "# We train this perceptron on only 2000 samples\n",
    "stack5 = trainStack([logreg1, rf1, xgb1], top_model5, X_train.iloc[:10000,:], y_train.iloc[:10000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's save the trained model\n",
    "filename = 'stacking_test/stack_random_forest.txt'\n",
    "with open(filename, 'wb') as fichier:\n",
    "    pickler = pk.Pickler(fichier)\n",
    "    pickler.dump(stack5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred5 = predictStack([logreg1, rf1, xgb1], stack5, X_test.iloc[:3000,:])\n",
    "y_train_pred5 = predictStack([logreg1, rf1, xgb1], stack5, X_train.iloc[:10000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.739789</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>0.727293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.753775</td>\n",
       "      <td>0.755400</td>\n",
       "      <td>0.751616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision    Recall  F1_score\n",
       "Test    0.739789  0.731667  0.727293\n",
       "Train   0.753775  0.755400  0.751616"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res5 = displayPerformances(y_test.iloc[:3000,:], y_test_pred5, y_train.iloc[:10000,:], y_train_pred5)\n",
    "res5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are not better than with a neural network. We ought to try with a support vector machine now.\n",
    "\n",
    "#### SVM\n",
    "\n",
    "It is highly advised to scale the data before any SVM operation. Standard Sclaing it is !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('datasets/observations2.csv')\n",
    "y_train = pd.read_csv('datasets/labels2.csv')\n",
    "X_train.drop('id',axis=1,inplace=True)\n",
    "y_train.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "X_test = pd.read_csv('datasets/observations3.csv')\n",
    "y_test = pd.read_csv('datasets/labels3.csv')\n",
    "X_test.drop('id',axis=1,inplace=True)\n",
    "y_test.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# X_train_scaled = sc.fit_transform(X_train)\n",
    "# X_test_scaled = sc.transform(X_test);\n",
    "\n",
    "# The lines above were an error. We scaled the former data instead of scaling the inputs of the level 1 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "top_model_svm = svm.SVC(kernel = 'linear')\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# We train this model on only 2000 samples\n",
    "stack_svm = trainStack([logreg1, rf1, xgb1], top_model_svm, X_train.iloc[:2000,:], y_train.iloc[:2000,:], scaler = sc, fit_scaler = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_svm = predictStack([logreg1, rf1, xgb1], stack_svm, X_test.iloc[:1000,:], scaler = sc)\n",
    "y_train_pred_svm = predictStack([logreg1, rf1, xgb1], stack_svm, X_train.iloc[:2000,:], scaler =sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's save the trained model\n",
    "filename = 'stacking_test/stack_svm_linear.txt'\n",
    "with open(filename, 'wb') as fichier:\n",
    "    pickler = pk.Pickler(fichier)\n",
    "    pickler.dump(stack_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.737323</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.725185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.757957</td>\n",
       "      <td>0.7615</td>\n",
       "      <td>0.754580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision  Recall  F1_score\n",
       "Test    0.737323  0.7320  0.725185\n",
       "Train   0.757957  0.7615  0.754580"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_svm = displayPerformances(y_test.iloc[:1000,:], y_test_pred_svm, y_train.iloc[:2000,:], y_train_pred_svm)\n",
    "res_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with a different kernel because this time. The results are ok but maybe we can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_svm_rbf = svm.SVC(kernel = 'rbf', gamma = 0.5)\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# We train this model on only 2000 samples\n",
    "stack_svm_rbf = trainStack([logreg1, rf1, xgb1], top_model_svm_rbf, X_train.iloc[:2000,:], y_train.iloc[:2000,:], scaler = sc, fit_scaler = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_svm_rbf = predictStack([logreg1, rf1, xgb1], stack_svm_rbf, X_test.iloc[:1000,:], scaler = sc)\n",
    "y_train_pred_svm_rbf = predictStack([logreg1, rf1, xgb1], stack_svm_rbf, X_train.iloc[:2000,:], scaler = sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's save the trained model\n",
    "filename = 'stacking_test/stack_svm_rbf.txt'\n",
    "with open(filename, 'wb') as fichier:\n",
    "    pickler = pk.Pickler(fichier)\n",
    "    pickler.dump(stack_svm_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.737591</td>\n",
       "      <td>0.7340</td>\n",
       "      <td>0.728333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.760837</td>\n",
       "      <td>0.7645</td>\n",
       "      <td>0.758654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision  Recall  F1_score\n",
       "Test    0.737591  0.7340  0.728333\n",
       "Train   0.760837  0.7645  0.758654"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_svm_rbf = displayPerformances(y_test.iloc[:1000,:], y_test_pred_svm_rbf, y_train.iloc[:2000,:], y_train_pred_svm_rbf)\n",
    "res_svm_rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the results are a weeny bit better. Let's try with a different kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_svm_sigmoid = svm.SVC(kernel = 'sigmoid', coef0 = 1)\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# We train this model on only 2000 samples\n",
    "stack_svm_sigmoid = trainStack([logreg1, rf1, xgb1], top_model_svm_sigmoid, X_train.iloc[:10000,:], y_train.iloc[:10000,:], scaler = sc, fit_scaler = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_svm_sigmoid = predictStack([logreg1, rf1, xgb1], stack_svm_sigmoid, X_test.iloc[:2000,:], scaler = sc)\n",
    "y_train_pred_svm_sigmoid = predictStack([logreg1, rf1, xgb1], stack_svm_sigmoid, X_train.iloc[:10000,:], scaler = sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's save the trained model\n",
    "filename = 'stacking_test/stack_svm_sigmoid.txt'\n",
    "with open(filename, 'wb') as fichier:\n",
    "    pickler = pk.Pickler(fichier)\n",
    "    pickler.dump(stack_svm_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.749945</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.713253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.755968</td>\n",
       "      <td>0.7461</td>\n",
       "      <td>0.732821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision  Recall  F1_score\n",
       "Test    0.749945  0.7300  0.713253\n",
       "Train   0.755968  0.7461  0.732821"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_svm_sigmoid = displayPerformances(y_test.iloc[:2000,:], y_test_pred_svm_sigmoid, y_train.iloc[:10000,:], y_train_pred_svm_sigmoid)\n",
    "res_svm_sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with a different kernel because this time, the results are **worse**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_svm_poly = svm.SVC(kernel = 'poly', degree = 2, coef0 = 1)\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# We train this model on only 2000 samples\n",
    "stack_svm_poly = trainStack([logreg1, rf1, xgb1], top_model_svm_poly, X_train.iloc[:10000,:], y_train.iloc[:10000,:], scaler = sc, fit_scaler = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_svm_poly = predictStack([logreg1, rf1, xgb1], stack_svm_poly, X_test.iloc[:2000,:], scaler = sc)\n",
    "y_train_pred_svm_poly = predictStack([logreg1, rf1, xgb1], stack_svm_poly, X_train.iloc[:10000,:], scaler = sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's save the trained model\n",
    "filename = 'stacking_test/stack_svm_poly.txt'\n",
    "with open(filename, 'wb') as fichier:\n",
    "    pickler = pk.Pickler(fichier)\n",
    "    pickler.dump(stack_svm_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.742472</td>\n",
       "      <td>0.7425</td>\n",
       "      <td>0.738165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.752244</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.751212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision  Recall  F1_score\n",
       "Test    0.742472  0.7425  0.738165\n",
       "Train   0.752244  0.7542  0.751212"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_svm_poly = displayPerformances(y_test.iloc[:2000,:], y_test_pred_svm_poly, y_train.iloc[:10000,:], y_train_pred_svm_poly)\n",
    "res_svm_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not too bad actually. However, we will see below that a majority vote is just a bit better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Majority vote\n",
    "\n",
    "We did still did not implemant a majority vote on the result given by our level 0 classifiers. Maybe it's time. However, one should keep in mind that ensemble learning and stacking may behave better with **a lot more level 0 classifiers** than currently. Indeed, to take a majority vote, it may seem better to have a lot of different outputs from level 0 learners. Anyway, we'll keep it short with our 3 classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorityVote(first_models, X_train):\n",
    "    \"\"\"\n",
    "    Input : list of learners, np.array (N,d)\n",
    "    Output : np.array (N,)\n",
    "    The function takes the level 0 trained learners, and the training observations. It returns the array containing the majority\n",
    "    vote coming from the level-0 classifiers.\n",
    "    \"\"\"\n",
    "    \n",
    "    X_stacked = stacked_dataset(first_models, X_train)\n",
    "    res = np.array(X_stacked.shape[0]*[0])\n",
    "    \n",
    "    for i in range(X_stacked.shape[0]):\n",
    "        line = X_stacked[i,:]\n",
    "        if (line == 1).sum() > (line == 0).sum():\n",
    "            res[i] = 1\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [1 1 0]\n",
      " [1 1 1]\n",
      " [0 0 0]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred6 = majorityVote([logreg1, rf1, xgb1], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.739789</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>0.727293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.746376</td>\n",
       "      <td>0.744221</td>\n",
       "      <td>0.738814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision    Recall  F1_score\n",
       "Test    0.739789  0.731667  0.727293\n",
       "Train   0.746376  0.744221  0.738814"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The test dataframes are meaningless here but we keep them for they are mandatory arguments to the function\n",
    "res6 = displayPerformances(y_test.iloc[:3000,:], y_test_pred5, y_train, y_train_pred6)\n",
    "res6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the best score hitherto, but still <font color = purple>not a breakthrough</font>, we definitely need more level-0 classifiers. Hopefully, since we do not need a training set and a test set, we can use 6 of the pretrained level-0 classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the pretrained models\n",
    "logreg2, rf2, xgb2 = None, None, None\n",
    "\n",
    "with open('stacking_test/logreg2.txt','rb') as fichier:\n",
    "    pickler = pk.Unpickler(fichier)\n",
    "    logreg2 = pickler.load()\n",
    "\n",
    "with open('stacking_test/random_forest_2.txt','rb') as fichier:\n",
    "    pickler = pk.Unpickler(fichier)\n",
    "    rf2 = pickler.load()\n",
    "    \n",
    "with open('stacking_test/xgb_2.txt','rb') as fichier:\n",
    "    pickler = pk.Unpickler(fichier)\n",
    "    xgb2 = pickler.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets. Since the models were trained on the first part of the dataset, we must choose different datasets this\n",
    "# time, for instance the second subsets\n",
    "X_train = pd.read_csv('datasets/observations3.csv')\n",
    "y_train = pd.read_csv('datasets/labels3.csv')\n",
    "X_train.drop('id',axis=1,inplace=True)\n",
    "y_train.drop('Unnamed: 0',axis=1,inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred7 = majorityVote([logreg1, rf1, xgb1, logreg2, rf2, xgb2], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.747908</td>\n",
       "      <td>0.743089</td>\n",
       "      <td>0.740407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision    Recall  F1_score\n",
       "Test    1.000000  1.000000  1.000000\n",
       "Train   0.747908  0.743089  0.740407"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The test dataframes are meaningless here but we keep them for they are mandatory arguments to the function\n",
    "res7 = displayPerformances(y_test.iloc[:3000,:], y_test.iloc[:3000,:], y_train, y_train_pred7)\n",
    "res7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **F1-score increased by 0.2%** which is still practically nothing. We probably reached the limit of what we could do with very simple, yet not so efficient classifiers. We need <font color = purple>more complex level-0 models</font> and we also need a <font color = purple>larger amount</font> of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With our own models\n",
    "\n",
    "Now that our own level 0 models have been trained, with our own parameters, we can finally implement the stacking methods overviewed previously.\n",
    "\n",
    "## Stacking : logistic regression\n",
    "The level 1 classifier is a logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.20.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.preprocessing.label module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.20.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.weight_boosting module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.20.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator AdaBoostClassifier from version 0.20.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Let's import a bunch of the level-0 classifiers\n",
    "level0_models = []\n",
    "level0_nn = []\n",
    "\n",
    "dir_name = 'zero_level_models'\n",
    "file_list = os.listdir(dir_name)\n",
    "\n",
    "for f in file_list:        \n",
    "    if 'model1_' in f:\n",
    "        with open(dir_name+'/'+f,'rb') as file:\n",
    "            pickler = pk.Unpickler(file)\n",
    "            try:\n",
    "                temp = pickler.load()\n",
    "                level0_models.append(temp)\n",
    "            except:\n",
    "                continue\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets. Since the models were trained on the first part of the dataset, we must choose different datasets this\n",
    "# time, for instance the second subsets\n",
    "X_train = pd.read_csv('datasets/observations2.csv')\n",
    "y_train = pd.read_csv('datasets/labels2.csv')\n",
    "X_train.drop('id',axis=1,inplace=True)\n",
    "y_train.drop('Unnamed: 0',axis=1,inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to import the test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('datasets/observations3.csv')\n",
    "y_test = pd.read_csv('datasets/labels3.csv')\n",
    "X_test.drop('id',axis=1,inplace=True)\n",
    "y_test.drop('Unnamed: 0',axis=1,inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model1 = LogisticRegression();\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "stack1 = trainStack(level0_models, top_model1, X_train.iloc[:5000,:], y_train.iloc[:5000,:], scaler = sc, fit_scaler = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = predictStack(level0_models, stack1, X_test.iloc[:5000,:], scaler = sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the results\n",
    "y_train_pred = predictStack(level0_models, stack1, X_train.iloc[:5000,:], scaler = sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.326727</td>\n",
       "      <td>0.5716</td>\n",
       "      <td>0.415788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.5888</td>\n",
       "      <td>0.436625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision  Recall  F1_score\n",
       "Test    0.326727  0.5716  0.415788\n",
       "Train   0.757919  0.5888  0.436625"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = displayPerformances(y_test.iloc[:5000,:], y_predicted, y_train.iloc[:5000,:],y_train_pred)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need to save this model that performs quite badly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking : neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model2 = Sequential()\n",
    "top_model2.add(Dense(25, input_dim=15, activation='relu'))\n",
    "top_model2.add(Dense(2, activation='softmax'))\n",
    "top_model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les résultats agglomérés des modèles ressemblent à ça : [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "stack2 = trainStack(level0_models, top_model2, X_train.iloc[:4000,:], y_train.iloc[:4000,:], is_MLP = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  0\n",
       "3  1\n",
       "4  0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filename = 'stacking_test/stack_MLP1.h5'\n",
    "# stack2.save(filename)\n",
    "y_train.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les résultats agglomérés des modèles ressemblent à ça : [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_predicted2 = predictStack(level0_models, stack2, X_test.iloc[:4000,:])\n",
    "y_pred_flat2 = probabilitiesToClass(y_predicted2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les résultats agglomérés des modèles ressemblent à ça : [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred2 = predictStack(level0_models, stack2, X_train.iloc[:4000,:])\n",
    "y_train_pred_flat2 = probabilitiesToClass(y_train_pred2);        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.302500</td>\n",
       "      <td>0.55000</td>\n",
       "      <td>0.390323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.758368</td>\n",
       "      <td>0.59125</td>\n",
       "      <td>0.439640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision   Recall  F1_score\n",
       "Test    0.302500  0.55000  0.390323\n",
       "Train   0.758368  0.59125  0.439640"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = displayPerformances(y_test.iloc[:4000,:], y_pred_flat2, y_train.iloc[:4000,:],y_train_pred_flat2)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking : majority vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the best score hitherto, but still <font color = purple>not a breakthrough</font>, we definitely need more level-0 classifiers. Hopefully, since we do not need a training set and a test set, we can use 6 of the pretrained level-0 classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les résultats agglomérés des modèles ressemblent à ça : [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred7 = majorityVote(level0_models, X_train.iloc[:10000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.747908</td>\n",
       "      <td>0.743089</td>\n",
       "      <td>0.740407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision    Recall  F1_score\n",
       "Test    1.000000  1.000000  1.000000\n",
       "Train   0.747908  0.743089  0.740407"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The test dataframes are meaningless here but we keep them for they are mandatory arguments of the function\n",
    "res7 = displayPerformances(y_test.iloc[:3000,:], y_test.iloc[:3000,:], y_train, y_train_pred7)\n",
    "res7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    " stackX = stacked_dataset(level0_models, X_train.iloc[:5000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 15, 15, ..., 15, 15, 15])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.array(stackX.shape[0]*[0])\n",
    "for i in range(stackX.shape[0]):\n",
    "    temp[i] = (stackX[i] == 1).sum()\n",
    "\n",
    "temp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(temp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the models trained on the second data set ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets. Since the models were trained on the first part of the dataset, we must choose different datasets this\n",
    "# time, for instance the second subsets\n",
    "X_train = pd.read_csv('datasets/observations1.csv')\n",
    "y_train = pd.read_csv('datasets/labels1.csv')\n",
    "X_train.drop('id',axis=1,inplace=True)\n",
    "y_train.drop('Unnamed: 0',axis=1,inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "#Let's import a bunch of the level-0 classifiers\n",
    "level0_models = []\n",
    "level0_nn = []\n",
    "\n",
    "dir_name = 'zero_level_models'\n",
    "file_list = os.listdir(dir_name)\n",
    "\n",
    "for f in file_list:        \n",
    "    if 'model2_' in f:\n",
    "        with open(dir_name+'/'+f,'rb') as file:\n",
    "            pickler = pk.Unpickler(file)\n",
    "            try:\n",
    "                temp = pickler.load()\n",
    "                level0_models.append(temp)\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    " stackX = stacked_dataset(level0_models, X_train.iloc[:5000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.array(stackX.shape[0]*[0])\n",
    "for i in range(stackX.shape[0]):\n",
    "    temp[i] = (stackX[i] == 1).sum()\n",
    "\n",
    "temp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(temp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "D:\\Programmes files (x86)\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.20.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib as jb\n",
    "\n",
    "model = jb.load('zero_level_models/model1_1.txt')\n",
    "\n",
    "y = model.predict(X_train_2.iloc[:1000,:])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
