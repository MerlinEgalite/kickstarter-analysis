{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "[1. Introduction](#Introduction)\n",
    "\n",
    "[2. Obtaining the data](#Obtaining-the-data)\n",
    "\n",
    "[3. Scrubbing the data](#Scrubbing-the-data)\n",
    "\n",
    "[4. SAving the data](#Saving-the-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Obtaining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the data and the required libraries will be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50) # Display up to 50 columns at a time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "plt.style.use('seaborn')\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12,5\n",
    "import glob # To read all csv files in the directory\n",
    "import seaborn as sns\n",
    "import calendar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_fscore_support\n",
    "import itertools\n",
    "import time\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most recent Kickstarter data from https://webrobots.io/kickstarter-datasets/ (from 14 March 2019) is stored in 56 separate csv files. The code below creates a list of all csv files beginning with 'Kickstarter' and concatenates them into one dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(f) for f in glob.glob('data/Kickstarter*.csv')], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backers_count</th>\n",
       "      <th>blurb</th>\n",
       "      <th>category</th>\n",
       "      <th>converted_pledged_amount</th>\n",
       "      <th>country</th>\n",
       "      <th>created_at</th>\n",
       "      <th>creator</th>\n",
       "      <th>currency</th>\n",
       "      <th>currency_symbol</th>\n",
       "      <th>currency_trailing_code</th>\n",
       "      <th>current_currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>disable_communication</th>\n",
       "      <th>friends</th>\n",
       "      <th>fx_rate</th>\n",
       "      <th>goal</th>\n",
       "      <th>id</th>\n",
       "      <th>is_backing</th>\n",
       "      <th>is_starrable</th>\n",
       "      <th>is_starred</th>\n",
       "      <th>launched_at</th>\n",
       "      <th>location</th>\n",
       "      <th>name</th>\n",
       "      <th>permissions</th>\n",
       "      <th>photo</th>\n",
       "      <th>pledged</th>\n",
       "      <th>profile</th>\n",
       "      <th>slug</th>\n",
       "      <th>source_url</th>\n",
       "      <th>spotlight</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>state</th>\n",
       "      <th>state_changed_at</th>\n",
       "      <th>static_usd_rate</th>\n",
       "      <th>urls</th>\n",
       "      <th>usd_pledged</th>\n",
       "      <th>usd_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>315</td>\n",
       "      <td>Babalus Shoes</td>\n",
       "      <td>{\"id\":266,\"name\":\"Footwear\",\"slug\":\"fashion/fo...</td>\n",
       "      <td>28645</td>\n",
       "      <td>US</td>\n",
       "      <td>1541459205</td>\n",
       "      <td>{\"id\":2094277840,\"name\":\"Lucy Conroy\",\"slug\":\"...</td>\n",
       "      <td>USD</td>\n",
       "      <td>$</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>1552539775</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>2108505034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1548223375</td>\n",
       "      <td>{\"id\":2462429,\"name\":\"Novato\",\"slug\":\"novato-c...</td>\n",
       "      <td>Babalus Children's Shoes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"key\":\"assets/023/667/205/a565fde5382d6b53276...</td>\n",
       "      <td>28645.0</td>\n",
       "      <td>{\"id\":3508024,\"project_id\":3508024,\"state\":\"in...</td>\n",
       "      <td>babalus-childrens-shoes</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "      <td>1548223375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>28645.0</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>A colorful Dia de los Muertos themed oracle de...</td>\n",
       "      <td>{\"id\":273,\"name\":\"Playing Cards\",\"slug\":\"games...</td>\n",
       "      <td>1950</td>\n",
       "      <td>US</td>\n",
       "      <td>1501684093</td>\n",
       "      <td>{\"id\":723886115,\"name\":\"Lisa Vollrath\",\"slug\":...</td>\n",
       "      <td>USD</td>\n",
       "      <td>$</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>1504976459</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>928751314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1502384459</td>\n",
       "      <td>{\"id\":2400549,\"name\":\"Euless\",\"slug\":\"euless-t...</td>\n",
       "      <td>The Ofrenda Oracle Deck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"key\":\"assets/017/766/989/dd9f18c773a8546d996...</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>{\"id\":3094785,\"project_id\":3094785,\"state\":\"ac...</td>\n",
       "      <td>the-ofrenda-oracle-deck</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>1504976459</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>271</td>\n",
       "      <td>Electra's long awaited, eclectic Debut Pop/Roc...</td>\n",
       "      <td>{\"id\":43,\"name\":\"Rock\",\"slug\":\"music/rock\",\"po...</td>\n",
       "      <td>22404</td>\n",
       "      <td>US</td>\n",
       "      <td>1348987533</td>\n",
       "      <td>{\"id\":323849677,\"name\":\"Electra\",\"is_registere...</td>\n",
       "      <td>USD</td>\n",
       "      <td>$</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>1371013395</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>928014092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1368421395</td>\n",
       "      <td>{\"id\":2423474,\"name\":\"Hollywood\",\"slug\":\"holly...</td>\n",
       "      <td>Record Electra's Debut Album (Pop, Rock, Class...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"key\":\"assets/011/433/681/489fd66f7861fefd8c8...</td>\n",
       "      <td>22404.0</td>\n",
       "      <td>{\"id\":359847,\"project_id\":359847,\"state\":\"inac...</td>\n",
       "      <td>record-electras-debut-album-pop-rock-classical</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>1371013395</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>22404.0</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   backers_count                                              blurb  \\\n",
       "0            315                                      Babalus Shoes   \n",
       "1             47  A colorful Dia de los Muertos themed oracle de...   \n",
       "2            271  Electra's long awaited, eclectic Debut Pop/Roc...   \n",
       "\n",
       "                                            category  \\\n",
       "0  {\"id\":266,\"name\":\"Footwear\",\"slug\":\"fashion/fo...   \n",
       "1  {\"id\":273,\"name\":\"Playing Cards\",\"slug\":\"games...   \n",
       "2  {\"id\":43,\"name\":\"Rock\",\"slug\":\"music/rock\",\"po...   \n",
       "\n",
       "   converted_pledged_amount country  created_at  \\\n",
       "0                     28645      US  1541459205   \n",
       "1                      1950      US  1501684093   \n",
       "2                     22404      US  1348987533   \n",
       "\n",
       "                                             creator currency currency_symbol  \\\n",
       "0  {\"id\":2094277840,\"name\":\"Lucy Conroy\",\"slug\":\"...      USD               $   \n",
       "1  {\"id\":723886115,\"name\":\"Lisa Vollrath\",\"slug\":...      USD               $   \n",
       "2  {\"id\":323849677,\"name\":\"Electra\",\"is_registere...      USD               $   \n",
       "\n",
       "   currency_trailing_code current_currency    deadline  disable_communication  \\\n",
       "0                    True              USD  1552539775                  False   \n",
       "1                    True              USD  1504976459                  False   \n",
       "2                    True              USD  1371013395                  False   \n",
       "\n",
       "  friends  fx_rate     goal          id is_backing  is_starrable is_starred  \\\n",
       "0     NaN      1.0  28000.0  2108505034        NaN         False        NaN   \n",
       "1     NaN      1.0   1000.0   928751314        NaN         False        NaN   \n",
       "2     NaN      1.0  15000.0   928014092        NaN         False        NaN   \n",
       "\n",
       "   launched_at                                           location  \\\n",
       "0   1548223375  {\"id\":2462429,\"name\":\"Novato\",\"slug\":\"novato-c...   \n",
       "1   1502384459  {\"id\":2400549,\"name\":\"Euless\",\"slug\":\"euless-t...   \n",
       "2   1368421395  {\"id\":2423474,\"name\":\"Hollywood\",\"slug\":\"holly...   \n",
       "\n",
       "                                                name permissions  \\\n",
       "0                           Babalus Children's Shoes         NaN   \n",
       "1                            The Ofrenda Oracle Deck         NaN   \n",
       "2  Record Electra's Debut Album (Pop, Rock, Class...         NaN   \n",
       "\n",
       "                                               photo  pledged  \\\n",
       "0  {\"key\":\"assets/023/667/205/a565fde5382d6b53276...  28645.0   \n",
       "1  {\"key\":\"assets/017/766/989/dd9f18c773a8546d996...   1950.0   \n",
       "2  {\"key\":\"assets/011/433/681/489fd66f7861fefd8c8...  22404.0   \n",
       "\n",
       "                                             profile  \\\n",
       "0  {\"id\":3508024,\"project_id\":3508024,\"state\":\"in...   \n",
       "1  {\"id\":3094785,\"project_id\":3094785,\"state\":\"ac...   \n",
       "2  {\"id\":359847,\"project_id\":359847,\"state\":\"inac...   \n",
       "\n",
       "                                             slug  \\\n",
       "0                         babalus-childrens-shoes   \n",
       "1                         the-ofrenda-oracle-deck   \n",
       "2  record-electras-debut-album-pop-rock-classical   \n",
       "\n",
       "                                          source_url  spotlight  staff_pick  \\\n",
       "0  https://www.kickstarter.com/discover/categorie...      False       False   \n",
       "1  https://www.kickstarter.com/discover/categorie...       True       False   \n",
       "2  https://www.kickstarter.com/discover/categorie...       True       False   \n",
       "\n",
       "        state  state_changed_at  static_usd_rate  \\\n",
       "0        live        1548223375              1.0   \n",
       "1  successful        1504976459              1.0   \n",
       "2  successful        1371013395              1.0   \n",
       "\n",
       "                                                urls  usd_pledged  \\\n",
       "0  {\"web\":{\"project\":\"https://www.kickstarter.com...      28645.0   \n",
       "1  {\"web\":{\"project\":\"https://www.kickstarter.com...       1950.0   \n",
       "2  {\"web\":{\"project\":\"https://www.kickstarter.com...      22404.0   \n",
       "\n",
       "        usd_type  \n",
       "0  international  \n",
       "1       domestic  \n",
       "2  international  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataframe contains 209,222 projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209222"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Scrubbing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the data will be cleaned and pre-processed in order to allow for exploratory data analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting and dropping columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 209222 projects in the dataset, there are 26958 which are listed more than once.\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates of individual projects\n",
    "print(f\"Of the {len(df)} projects in the dataset, there are {len(df[df.duplicated(subset='id')])} which are listed more than once.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates are an issue in this dataset and will need to be dealt with. Further cleaning of the data will help clarify which duplicates, if any, need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209222 entries, 0 to 209221\n",
      "Data columns (total 37 columns):\n",
      "backers_count               209222 non-null int64\n",
      "blurb                       209214 non-null object\n",
      "category                    209222 non-null object\n",
      "converted_pledged_amount    209222 non-null int64\n",
      "country                     209222 non-null object\n",
      "created_at                  209222 non-null int64\n",
      "creator                     209222 non-null object\n",
      "currency                    209222 non-null object\n",
      "currency_symbol             209222 non-null object\n",
      "currency_trailing_code      209222 non-null bool\n",
      "current_currency            209222 non-null object\n",
      "deadline                    209222 non-null int64\n",
      "disable_communication       209222 non-null bool\n",
      "friends                     300 non-null object\n",
      "fx_rate                     209222 non-null float64\n",
      "goal                        209222 non-null float64\n",
      "id                          209222 non-null int64\n",
      "is_backing                  300 non-null object\n",
      "is_starrable                209222 non-null bool\n",
      "is_starred                  300 non-null object\n",
      "launched_at                 209222 non-null int64\n",
      "location                    208996 non-null object\n",
      "name                        209222 non-null object\n",
      "permissions                 300 non-null object\n",
      "photo                       209222 non-null object\n",
      "pledged                     209222 non-null float64\n",
      "profile                     209222 non-null object\n",
      "slug                        209222 non-null object\n",
      "source_url                  209222 non-null object\n",
      "spotlight                   209222 non-null bool\n",
      "staff_pick                  209222 non-null bool\n",
      "state                       209222 non-null object\n",
      "state_changed_at            209222 non-null int64\n",
      "static_usd_rate             209222 non-null float64\n",
      "urls                        209222 non-null object\n",
      "usd_pledged                 209222 non-null float64\n",
      "usd_type                    208742 non-null object\n",
      "dtypes: bool(5), float64(5), int64(7), object(20)\n",
      "memory usage: 52.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking column information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns contain very few nun-null entries, and can be dropped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that are mostly null\n",
    "df.drop(['friends', 'is_backing', 'is_starred', 'permissions'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other columns are not useful for the purposes of this project, and can also be dropped for these reasons:\n",
    "\n",
    "- converted_pledged_amount - most currencies are converted into USD in this column, but not all. Instead, the 'usd_pledged' column will be used as these all use the same currency (the dollar).\n",
    "- creator - most projects are by different people, and so this cannot be usefully used to group or categorise projects, and is not useful in a machine learning context.\n",
    "- currency - all currency values will be used as/converted to dollars, so that they can be evaluated together. It is not necessary to keep the original record because of this, and because it will be highly correlated with country (which will be kept).\n",
    "- currency_symbol - as above.\n",
    "- currency_trailing_code - as above.\n",
    "- current_currency - as above.\n",
    "- fx_rate - this is used to create 'converted_pledged_amount' from 'pledged', but does not always convert to dollars so can be dropped in favour of 'static_usd_rate' which always converts to dollars.\n",
    "- photo - image processing/computer vision will not be used in this project.\n",
    "- pledged - data in this column is stored in native currencies, so this will be dropped in favour of 'usd_pledged' which is all in the same currency (dollars).\n",
    "- profile - this column contains a combination of information from other columns (e.g. id, state, dates, url).\n",
    "- slug - this is simply the 'name' column with hyphens instead of spaces.\n",
    "- source_url - the sites that the rows were each scraped from is not useful for building a model, as each is unique to an id.\n",
    "- spotlight - projects can only be spotlighted after they are already successful, so this will be entirely correlated with successful projects.\n",
    "- state_changed_at - this is the same as deadline for most projects. The only exceptions are for projects which were cancelled before their deadline, but they will not be included in this analysis.\n",
    "- urls - as with source_url.\n",
    "- usd_type - it is unclear what this column means, but it is unlikely to be necessary since all currency values will be converted to dollars, and other currency information has been dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping columns that aren't useful\n",
    "df.drop(['converted_pledged_amount', 'creator', 'currency', 'currency_symbol', 'currency_trailing_code', 'current_currency', 'fx_rate', 'photo', 'pledged', 'profile', 'slug', 'source_url', 'spotlight', 'state_changed_at', 'urls', 'usd_type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting datetime columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns containing dates are currently stored in unix time, and need to be converted to datetime. Because they have been converted from unix, all times are in UTC/GMT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dates from unix to datetime\n",
    "cols_to_convert = ['created_at', 'deadline', 'launched_at']\n",
    "for c in cols_to_convert:\n",
    "    df[c] = pd.to_datetime(df[c], origin='unix', unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains projects added to Kickstarter between 22 April 2009 and 14 March 2019.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The dataset contains projects added to Kickstarter between {min(df.created_at).strftime('%d %B %Y')} and {max(df.created_at).strftime('%d %B %Y')}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual columns will now be pre-processed, and additional features engineered, where necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Blurb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural language processing is beyond the scope of this project. The length of the blurbs written by project creators will be calculated though, in case this is useful for the model (e.g. people preferring to read shorter or longer blurbs when choosing what to fund). The original blurb variable will then be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count length of each blurb\n",
    "df['blurb_length'] = df['blurb'].str.split().str.len()\n",
    "\n",
    "# Drop blurb variable\n",
    "df.drop('blurb', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Category**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category variable is currently stored as a string, although it was clearly originally a dictionary. The example below shows that each project has both a category (e.g. games) and a sub-category (e.g. tabletop games). Both will be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\":266,\"name\":\"Footwear\",\"slug\":\"fashion/footwear\",\"position\":5,\"parent_id\":9,\"color\":16752598,\"urls\":{\"web\":{\"discover\":\"http://www.kickstarter.com/discover/categories/fashion/footwear\"}}}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example category value\n",
    "df.iloc[0]['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         {\"id\":266,\"name\":\"Footwear\",\"slug\":\"fashion/fo...\n",
      "1         {\"id\":273,\"name\":\"Playing Cards\",\"slug\":\"games...\n",
      "2         {\"id\":43,\"name\":\"Rock\",\"slug\":\"music/rock\",\"po...\n",
      "3         {\"id\":273,\"name\":\"Playing Cards\",\"slug\":\"games...\n",
      "4         {\"id\":48,\"name\":\"Nonfiction\",\"slug\":\"publishin...\n",
      "                                ...                        \n",
      "209217    {\"id\":34,\"name\":\"Tabletop Games\",\"slug\":\"games...\n",
      "209218    {\"id\":38,\"name\":\"Electronic Music\",\"slug\":\"mus...\n",
      "209219    {\"id\":52,\"name\":\"Hardware\",\"slug\":\"technology/...\n",
      "209220    {\"id\":295,\"name\":\"Festivals\",\"slug\":\"film & vi...\n",
      "209221    {\"id\":13,\"name\":\"Journalism\",\"slug\":\"journalis...\n",
      "Name: category, Length: 209222, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extracting the relevant sub-category section from the string\n",
    "f = lambda x: x['category'].split('/')[1].split('\",\"position')[0]\n",
    "df['sub_category'] = df.apply(f, axis=1)\n",
    "print(df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              fashion\n",
      "1                games\n",
      "2                music\n",
      "3                games\n",
      "4           publishing\n",
      "              ...     \n",
      "209217           games\n",
      "209218           music\n",
      "209219      technology\n",
      "209220    film & video\n",
      "209221      journalism\n",
      "Name: category, Length: 209222, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extracting the relevant category section from the string, and replacing the original category variable\n",
    "f = lambda x: x['category'].split('\"slug\":\"')[1].split('\",\"position\"')[0].split('/')[0]\n",
    "df['category'] = df.apply(f, axis=1)\n",
    "print(df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15 unique categories and 145 unique sub-categories.\n"
     ]
    }
   ],
   "source": [
    "# Counting the number of unique categories\n",
    "print(f\"There are {df.category.nunique()} unique categories and {df.sub_category.nunique()} unique sub-categories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disable_communication**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99.7% of project owners did not disable communication with their backers (unsurprisingly). Because nearly all projects have the same value for this variable, it will be dropped as it does not provide much information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.997022\n",
       "True     0.002978\n",
       "Name: disable_communication, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the proportions of each category\n",
    "df.disable_communication.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('disable_communication', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal amount of funding for each project is currently recorded in native currencies. In order to allow for fair comparisons between projects, goals will be converted into dollars (as amount pledged already is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate new column 'usd_goal' as goal * static_usd_rate\n",
    "df['usd_goal'] = round(df['goal'] * df['static_usd_rate'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping goal and static_usd_rate\n",
    "df.drop(['goal', 'static_usd_rate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is_starrable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 3.3% of projects were starrable by users. Although this is only a very small proportion, whether or not a project was liked and saved by users is likely to be informative about whether or not a project was successful, so the variable will be kept for now and assessed again once irrelevant rows have been dropped, to check it is still useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.967403\n",
       "True     0.032597\n",
       "Name: is_starrable, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figure out what this is, and do a count_values() to figure out whether it's worth including or mostly FALSE\n",
    "df.is_starrable.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Location**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The location field contains the town/city that a project originates from, as well as the country. There are a large number (15,235) of unique locations. Because the country is already recorded separately in the country field, and there are such a large number of unique categories (making one-hot encoding not useful, particularly as there are likely to be a lot of smaller towns and cities with very few projects), the column will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\":2462429,\"name\":\"Novato\",\"slug\":\"novato-ca\",\"short_name\":\"Novato, CA\",\"displayable_name\":\"Novato, CA\",\"localized_name\":\"Novato\",\"country\":\"US\",\"state\":\"CA\",\"type\":\"Town\",\"is_root\":false,\"urls\":{\"web\":{\"discover\":\"https://www.kickstarter.com/discover/places/novato-ca\",\"location\":\"https://www.kickstarter.com/locations/novato-ca\"},\"api\":{\"nearby_projects\":\"https://api.kickstarter.com/v1/discover?signature=1552595066.49b64db66a5124f5831752d055cd09aff20cc652&woe_id=2462429\"}}}'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example location value\n",
    "df.iloc[0]['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15235"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the number of unique locations\n",
    "df.location.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping location\n",
    "df.drop('location', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of project names will be calculated, in case this is useful for the model. The original name variable will then be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count length of each name\n",
    "df['name_length'] = df['name'].str.split().str.len()\n",
    "# Drop name variable\n",
    "df.drop('name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usd_pledged**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column requires rounding to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['usd_pledged'] = round(df['usd_pledged'],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional calculated features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional features can be calculated from the existing features, which may also help to predict whether a project is successfully funded. The features to be added are: time from creation to launch, campaign length, launch day of week, deadline day of week, launch month, deadline month, launch time of day, deadline time of day and mean pledge per backer. Original datetime values and the mean pledge per backer will be kept in for now for EDA purposes, but will be removed later, before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time between creating and launching a project\n",
    "df['creation_to_launch_days'] = df['launched_at'] - df['created_at']\n",
    "df['creation_to_launch_days'] = df['creation_to_launch_days'].dt.round('d').dt.days # Rounding to nearest days, then showing as number only\n",
    "# Or could show as number of hours:\n",
    "# df['creation_to_launch_hours'] = df['launched_at'] - df['created_at']\n",
    "# df['creation_to_launch_hours'] = df['creation_to_launch_hours'].dt.round('h') / np.timedelta64(1, 'h') \n",
    "\n",
    "# Campaign length\n",
    "df['campaign_days'] = df['deadline'] - df['launched_at']\n",
    "df['campaign_days'] = df['campaign_days'].dt.round('d').dt.days # Rounding to nearest days, then showing as number only\n",
    "\n",
    "# Launch day of week\n",
    "df['launch_day'] = df['launched_at'].dt.weekday_name\n",
    "\n",
    "# Deadline day of week\n",
    "df['deadline_day'] = df['deadline'].dt.weekday_name\n",
    "\n",
    "# Launch month\n",
    "df['launch_month'] = df['launched_at'].dt.month_name()\n",
    "\n",
    "# Deadline month\n",
    "df['deadline_month'] = df['deadline'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Launch time\n",
    "df['launch_hour'] = df['launched_at'].dt.hour # Extracting hour from launched_at\n",
    "\n",
    "def two_hour_launch(row):\n",
    "    '''Creates two hour bins from the launch_hour column'''\n",
    "    if row['launch_hour'] in (0,1):\n",
    "        return '12am-2am'\n",
    "    if row['launch_hour'] in (2,3):\n",
    "        return '2am-4am'\n",
    "    if row['launch_hour'] in (4,5):\n",
    "        return '4am-6am'\n",
    "    if row['launch_hour'] in (6,7):\n",
    "        return '6am-8am'\n",
    "    if row['launch_hour'] in (8,9):\n",
    "        return '8am-10am'\n",
    "    if row['launch_hour'] in (10,11):\n",
    "        return '10am-12pm'\n",
    "    if row['launch_hour'] in (12,13):\n",
    "        return '12pm-2pm'\n",
    "    if row['launch_hour'] in (14,15):\n",
    "        return '2pm-4pm'\n",
    "    if row['launch_hour'] in (16,17):\n",
    "        return '4pm-6pm'\n",
    "    if row['launch_hour'] in (18,19):\n",
    "        return '6pm-8pm'\n",
    "    if row['launch_hour'] in (20,21):\n",
    "        return '8pm-10pm'\n",
    "    if row['launch_hour'] in (22,23):\n",
    "        return '10pm-12am'\n",
    "    \n",
    "df['launch_time'] = df.apply(two_hour_launch, axis=1) # Calculates bins from launch_time\n",
    "\n",
    "df.drop('launch_hour', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deadline time\n",
    "df['deadline_hour'] = df['deadline'].dt.hour # Extracting hour from deadline\n",
    "\n",
    "def two_hour_deadline(row):\n",
    "    '''Creates two hour bins from the deadline_hour column'''\n",
    "    if row['deadline_hour'] in (0,1):\n",
    "        return '12am-2am'\n",
    "    if row['deadline_hour'] in (2,3):\n",
    "        return '2am-4am'\n",
    "    if row['deadline_hour'] in (4,5):\n",
    "        return '4am-6am'\n",
    "    if row['deadline_hour'] in (6,7):\n",
    "        return '6am-8am'\n",
    "    if row['deadline_hour'] in (8,9):\n",
    "        return '8am-10am'\n",
    "    if row['deadline_hour'] in (10,11):\n",
    "        return '10am-12pm'\n",
    "    if row['deadline_hour'] in (12,13):\n",
    "        return '12pm-2pm'\n",
    "    if row['deadline_hour'] in (14,15):\n",
    "        return '2pm-4pm'\n",
    "    if row['deadline_hour'] in (16,17):\n",
    "        return '4pm-6pm'\n",
    "    if row['deadline_hour'] in (18,19):\n",
    "        return '6pm-8pm'\n",
    "    if row['deadline_hour'] in (20,21):\n",
    "        return '8pm-10pm'\n",
    "    if row['deadline_hour'] in (22,23):\n",
    "        return '10pm-12am'\n",
    "    \n",
    "df['deadline_time'] = df.apply(two_hour_deadline, axis=1) # Calculates bins from launch_time\n",
    "\n",
    "df.drop('deadline_hour', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean pledge per backer\n",
    "df['pledge_per_backer'] = round(df['usd_pledged']/df['backers_count'],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking for null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are eight projects without a blurb_length, i.e. without a blurb. These can be replaced with a length of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing null values for blurb_length with 0\n",
    "df.blurb_length.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming there are no null values remaining\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping rows**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to predict whether projects succeed or fail. The dataset also includes canceled, live (i.e. not yet finished) and suspended projects. These will now be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of projects of different states\n",
    "df.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping projects which are not successes or failures\n",
    "df = df[df['state'].isin(['successful', 'failed'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confirming that the most recent deadline is the day on which the data was scraped, i.e. there are no projects which have yet to be resolved into either successes or failures\n",
    "max(df.deadline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping duplicates**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demonstrated above, some projects are included in the dataset more than once. Duplicates will now be assessed and removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking for duplicates of individual projects, and sorting by id\n",
    "duplicates = df[df.duplicated(subset='id')]\n",
    "print(f\"Of the {len(df)} projects in the dataset, there are {len(df[df.duplicated(subset='id')])} which are listed more than once.\")\n",
    "print(f\"Of these, {len(df[df.duplicated()])} have every value in common between duplicates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates which have every value in common\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(df[df.duplicated(subset='id')]), \"duplicated projects remain.\")\n",
    "duplicated = df[df.duplicated(subset='id', keep=False)].sort_values(by='id')\n",
    "duplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing rows for each duplicated project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get list of index numbers for duplicated ids\n",
    "dup_ids = duplicated.id.unique()\n",
    "for i in dup_ids:\n",
    "    index1 = duplicated[duplicated.id == i][:1].index.values\n",
    "    index2 = duplicated[duplicated.id == i][1:2].index.values\n",
    "    print(index1, index2)\n",
    "    #print(duplicated.loc[index1] == duplicated.loc[index2]) # produces TypeError: Could not compare [None] with block values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show that for each pair of duplicates, there are differences in the usd_pledge and usd_goal columns. The differences are only in the order of a few cents or dollars, so it does not make much difference which one is kept. Therefore the first one of each pair will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='id', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting the index**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The id will now be set as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting the id column as the index\n",
    "df.set_index('id', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features were retained for EDA purposes, but now need to be dropped in order to use machine learning models. This includes datetime features, features that are related to outcomes (e.g. the amount pledged and the number of backers) rather than related to the properties of the project itself (e.g. category, goal, length of campaign), categorical features which would result in too many one-hot encoded features (sub_category), and features that only have one category (is_starrable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping columns and creating new dataframe\n",
    "df_transformed = df.drop(['backers_count', 'created_at', 'deadline', 'is_starrable', 'launched_at', 'usd_pledged', 'sub_category', 'pledge_per_backer'], axis=1)\n",
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-collinearity will be checked for by assessing correlations between predictor features, as this can cause issues with some models. The multi-collinearity matrix below shows that this is not an issue:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dependent variable will now be converted into 1s (successful) and 0s (failure):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_transformed['state'] = df_transformed['state'].replace({'failed': 0, 'successful': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical features will now be one-hot encoded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting boolean features to string to include them in one-hot encoding\n",
    "df_transformed['staff_pick'] = df_transformed['staff_pick'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating dummy variables\n",
    "df_transformed = pd.get_dummies(df_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the dependent (y) and independent (X) features will be separated into separate datasets. Because the features are on different scales, independent features will be transformed and normalised using StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing skewed distributions\n",
    "cols_to_log = ['creation_to_launch_days', 'name_length', 'usd_goal']\n",
    "df_transformed[cols_to_log].hist(figsize=(8,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing 0s with 0.01 and log-transforming\n",
    "for col in cols_to_log:\n",
    "    df_transformed[col] = df_transformed[col].astype('float64').replace(0.0, 0.01)\n",
    "    df_transformed[col] = np.log(df_transformed[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed[cols_to_log].hist(figsize=(8,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data can be prepared again for machine learning by separating X and y, and scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unscaled_log = df_transformed.drop('state', axis=1)\n",
    "y_log = df_transformed.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the data\n",
    "scaler = StandardScaler()\n",
    "X_log = pd.DataFrame(scaler.fit_transform(X_unscaled_log), columns=list(X_unscaled_log.columns))\n",
    "X_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log.to_csv('processed_datasets/observations.csv', header=X_log.columns)\n",
    "y_log = y_log.values\n",
    "y_log = pd.DataFrame(y_log)\n",
    "y_log.to_csv('processed_datasets/labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we should separate the dataset in three similar subsets for further trainings, validation and tests. More specifically, one part will be used to train the level 0 models, the second part will be used to train the level 1 model and the last subset will be used to test the whole stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X_log.values.shape[0]\n",
    "n_subset = n_samples//3\n",
    "\n",
    "X1 = X_log.iloc[:n_subset,:]\n",
    "X2 = X_log.iloc[n_subset:2*n_subset,:]\n",
    "X3 = X_log.iloc[2*n_subset:,:]\n",
    "\n",
    "y1 = y_log.iloc[:n_subset,:]\n",
    "y2 = y_log.iloc[n_subset:2*n_subset,:]\n",
    "y3 = y_log.iloc[2*n_subset:,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.to_csv('processed_datasets/observations1.csv', header=X1.columns )\n",
    "X2.to_csv('processed_datasets/observations2.csv', header=X2.columns )\n",
    "X3.to_csv('processed_datasets/observations3.csv', header=X3.columns )\n",
    "y1.to_csv('processed_datasets/labels1.csv')\n",
    "y2.to_csv('processed_datasets/labels2.csv')\n",
    "y3.to_csv('processed_datasets/labels3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
